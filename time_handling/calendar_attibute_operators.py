#!/usr/bin/env python3
# -*- coding: utf-8 -*-

#----------------#
# Import modules #
#----------------#

import calendar
import datetime
from pathlib import Path

import sys

import numpy as np
import pandas as pd

#-----------------------#
# Import custom modules #
#-----------------------#

# Find the path of the Python toolbox #
home_PATH = Path.home()
sys.path.append(str(home_PATH))

import get_pytools_path
fixed_path = get_pytools_path.return_custom_path()

# Enumerate custom modules and their paths #
#------------------------------------------#

custom_mod1_path = f"{fixed_path}/arrays_and_lists"
custom_mod2_path = f"{fixed_path}/parameters_and_constants"
custom_mod3_path = f"{fixed_path}/pandas_data_frames" 
custom_mod4_path = f"{fixed_path}/strings"
custom_mod5_path = f"{fixed_path}/time_handling"
                  
# Add the paths to the 'path' attribute of module 'sys' #
#-------------------------------------------------------#

sys.path.append(custom_mod1_path)
sys.path.append(custom_mod2_path)
sys.path.append(custom_mod3_path)
sys.path.append(custom_mod4_path)
sys.path.append(custom_mod5_path)

# Perform whole or partial module importations #
#----------------------------------------------#

from array_handler import count_unique_type_objects
import data_frame_handler
from global_parameters import basic_time_format_strs
from string_handler import find_substring_index, modify_obj_specs
from time_formatters import time_format_tweaker

#----------------------------------------------------#
# Define imported module(s)' function call shortcuts #
#----------------------------------------------------#

find_date_key = data_frame_handler.find_date_key
infer_time_frequency = data_frame_handler.infer_time_frequency
insert_row_in_df = data_frame_handler.insert_row_in_df
save2csv = data_frame_handler.save2csv
save2excel = data_frame_handler.save2excel

#------------------#
# Define functions #
#------------------#

def standardize_calendar(obj,
                         file_path,
                         obj_type="pandas",
                         interpolation_method=None,
                         order=None,
                         save_as_new_obj=False, 
                         extension=None, 
                         separator=",",
                         save_index=False,
                         save_header=False):
    
    """
    **Function global note** 
    ------------------------
    
    This functions imports 'netcdf_handler' which at the same imports xarray.
    But not always will the conda environment have installed xarray
    or the user will not fot_resee any need of installing it,
    mainly because the basic libraries are already installed.
    
    To this day, taking account the structure of the modules
    and practicity and cleanliness of this function,
    the 'netcdf_handler' module will only be imported here
    together with xarray.
    
    
    This function standardizes the given calendar of an object to gregorian
    and makes an interpolation ALONG ROWS (axis=0) to find the missing data.
    It usually happens when modelled atmospheric or land data is considered,
    when each model has its own calendar.
    This funcion is useful when several model data is handled at once.
    
    It only sticks to the limits of the time array pt_resent at the object;
    further reconstructions is a task left for the user.
    
    Parameters
    ----------
    obj : pd.DataFrame or xarray.Dataset
          or list of pd.DataFrame or xarray.Dataset.
          Object containing data. For each pd.DataFrame, if pt_resent,
          the first column must be of type datetime64.
    file_path : str or list of str
          String referring to the file name from which data object 
          has been extracted.
    save_as_new_obj : bool
          If True and object is pd.DataFrame, it is saved either
          as CSV or Excel containing one or more frames, the latter being
          desired by the user.
    extension : {"csv", "xlsx", "nc"}
          The first two only work if object is pd.DataFrame,
          while the third works if object is xarray.Dataset.
          If "csv" chosen, the whole data frame will be stored in a single
          document.
          On the other hand, if "xlsx" is selected, then all columns other
          than the time array will be introduced in separate tabs,
          together with the time array itself.
    separator : str
          String used to separate data columns.
          Default value is a comma (',').
    save_index : bool
          Boolean to choose whether to include a column into the excel document
          that identifies row numbers. Default value is False.
    save_header : bool
          Boolean to choose whether to include a row into the excel document
          that identifies column numbers. Default value is False.
    
    
    Returns
    -------
    obj : pd.DataFrame, xarray.Dataset 
          or xarray.DataArray.
          Object containing the standardized calendar to gregorian.
    
    Note
    ----
    There is no programatic way to store multiple sheets on a CSV file,
    as can be donde with Excel files, because CSV is rough, old format
    but mainly for data transport used.
    """
    
    obj_types = ["pandas", "xarray"]

    arg_names = standardize_calendar.__code__.co_varnames
    obj_type_arg_pos = find_substring_index(arg_names, "obj_type")
    
    if obj_type not in obj_types:
        raise ValueError(f"Wrong '{arg_names[obj_type_arg_pos]}' argument. "
                         f"Options are {obj_types}.")
        
    if obj_type == "pandas":

        if not isinstance(obj, list) and not isinstance(obj, np.ndarray):
            obj = [obj]
            
        if not isinstance(file_path, list) and not isinstance(file_path, np.ndarray):
            file_path = [file_path]
            
        obj_std_calendar = []
        len_objects = len(obj)
            
        # Check whether all objects passed in a list are of the same type #
        len_unique_type_list = count_unique_type_objects(obj)[-1]
        
        if len_unique_type_list > 1:
            raise ValueError("Not every object in the list is of the same type.")
            
        else:
            """It is supposed that every component is of the same type"""
            if isinstance(obj[0], pd.DataFrame):
                
                for (obj_num, obj), fp in zip(enumerate(obj), file_path):
                    
                    # Get the date key and time frequency #
                    time_col = find_date_key(obj)
                    time_freq = infer_time_frequency(obj.loc[:10,time_col])
                    
                    # Get the time array with possible missing datetimes #
                    time_shorter = obj.loc[:,time_col]
                    time_shorter_arr = time_format_tweaker(time_shorter)
                    ltm = len(time_shorter)
                   
                    # Construct full time array to compare with the previous array #
                    first_datetime = obj.iloc[0, 0]
                    last_datetime = obj.iloc[-1, 0]
                    
                    full_times = pd.date_range(first_datetime,
                                                last_datetime, 
                                                freq=time_freq)
                    lft = len(full_times)
                    
                    data_frames_remaining = len_objects - (obj_num+1) 
                    print(f"Data frames remaining: {data_frames_remaining}")
                    
                    # Compare both time arrays, even if they have the same length #
                    if ltm != lft:
                        for ft in full_times:
                            if ft not in time_shorter_arr:
                                
                                """Previous day of the missing date-time (indexing)"""
                                missing_date_yesterday\
                                = ft - datetime.timedelta(days=1)
                                index_yesterday\
                                = obj[obj[time_col]==missing_date_yesterday].index
                                
                                """Actual missing time"""
                                index_missing_time = int((index_yesterday + 1).to_numpy())
                                
                                missing_datetime\
                                = missing_date_yesterday + datetime.timedelta(days=1)
                                
                                """Define values to insert"""
                                values = np.append(missing_datetime,
                                                   np.repeat(np.nan, len(obj.columns[1:])))
                                
                                insert_row_in_df(obj, index_missing_time, values=values)
                    
                        # Reorder the data frame indexes #
                        obj = obj.sort_index().t_reset_index(drop=True)
                        obj.iloc[:, 1:] = obj.iloc[:, 1:].astype('d')
                                        
                        # Perform the interpolation, if requested #
                        if interpolation_method is not None:
                            
                            if (interpolation_method == "polynomial"\
                            or interpolation_method == "spline")\
                            and order is None:
                                raise ValueError("Please specify and order for the "
                                                  "interpolation method "
                                                  f"{interpolation_method}")
                        
                            # Fill the missing data as a   #
                            # consequence of missing dates #
                            print("Filling the missing data "
                                  "as a consequence of missing dates...")
                            
                            obj.iloc[:, 1:]\
                            = obj.iloc[:, 1:].interpolate(method=interpolation_method,
                                                          order=order)
                            
                    obj_std_calendar.append(obj)
        
                    # Save the object either as Excel or CSV document #
                    if save_as_new_obj:
                        
                        obj2change = "name_noext"
                        str2add = "_stdCalendar"
                        
                        saving_file_name = modify_obj_specs(fp,
                                                            obj2change,
                                                            new_obj=None,
                                                            str2add=str2add)
                        
                        if extension == "csv":        
                            
                            print("Saving data into a CSV document...")
                            save2csv(saving_file_name,
                                      obj,
                                      separator,
                                      save_index,
                                      save_header,
                                      date_format=basic_time_format_strs[time_freq])
                            
                        elif extension == "xlsx":
                            
                            frame_dict = {}
                            obj_cols = obj.columns
                            
                            for grid_col in obj_cols[1:]:
                                
                                excel_sheet_name = grid_col
                                frame_dict[excel_sheet_name]\
                                = obj.loc[:, [time_col, grid_col]]
                                
                                print("Writing and storing data "
                                      "into an excel document...")
                                save2excel(saving_file_name,
                                            frame_dict,
                                            save_index,
                                            save_header)
            
                        else:
                            raise ValueError("Wrong extension choice. "
                                             "Options for a Pandas data frame "
                                             "are {'csv', 'xlsx'}.")
                            
        return obj_std_calendar
    
    elif obj_type == "xarray":
        
        # Import module and custom modules here by convenience #
        #------------------------------------------------------#
        
        import xarray as xr
        import netcdf_handler
        
        # Define imported module(s)' function call shortcuts by convenience #
        #-------------------------------------------------------------------#
            
        find_time_dimension = netcdf_handler.find_time_dimension
        get_file_dimensions = netcdf_handler.get_file_dimensions
 
        # TODO: develop the case for xarray.Dataset objects #
        # elif isinstance(obj[0], xr.Dataset)\
        # or isinstance(obj[0], xr.DataArray):

def week_range(date):
    
    """
    Finds the week day-range, i.e, the first and last day of the week
    where a given calendar day lies on.
    In Europe weeks start on Monday and end on Sunday.
    
    Isocalendar calculates the year, week of the year, 
    and day of the week ('dow' === 'day of week'), where
    'dow' is Mon = 1, ... , Sat = 6, Sun = 7
    
    Parameters
    ----------
    date : pandas._libs.tslibs.timestamps.Timestamp
          Timestamp format string that contains a particular date time.
    start_date, end_date: str
          Pair of strings that refer, respectively, to the first and
          last days of the week that lies the given date within.
    """
    
    if isinstance(date, pd._libs.tslibs.timestamps.Timestamp):
        
        dow = date.isocalendar()[-1]

        # Find the first day of the week #
        #--------------------------------#
        
        if dow == 1:
            # Since we want to start with Monday, let's test for that condition.
            start_date = date
        else:
            # Otherwise, subtract the 'dow' number days 
            # that have passed from Monday to get the first day.
            start_date = date - (datetime.timedelta(dow) - datetime.timedelta(1))

        # Now, add 6 for the last day of the week (i.e., count up to Sunday) #
        #--------------------------------------------------------------------#
        
        end_date = start_date + datetime.timedelta(days=6)

        return (start_date, end_date)
        
    else:
        raise ValueError("The date given is not a Timestamp") 
        
        
def nearest_leap_year(year):
    
    year_isleap = leap_year_detector(year, year)
    
    if not year_isleap:
        year_list = list(range(year-4, year+4))
        lyl = len(year_list)
        
        nearest_leap_year_idx = [i
                                 for i in range(lyl) 
                                 if leap_year_detector(year_list[i], year_list[i])]
        
        min_idx = nearest_leap_year_idx[0]
        max_idx = nearest_leap_year_idx[1]
        
        min_idx_year_diff = abs(year_list[min_idx] - year)
        max_idx_year_diff = abs(year_list[max_idx] - year)
        
        if min_idx_year_diff > 1 and min_idx_year_diff != 2:
            nearest_lp_year = year_list[max_idx]
        elif max_idx_year_diff > 1 and max_idx_year_diff != 2:
            nearest_lp_year = year_list[min_idx]
        elif min_idx_year_diff == max_idx_year_diff:
            nearest_lp_year = f"{year_list[min_idx]} or {year_list[max_idx]}"
        
    else:
        nearest_lp_year = year
        
    return nearest_lp_year


def leap_year_detector(start_year, end_year, return_days=False):
    
    if isinstance(start_year, str):
        start_year = int(start_year)
    if isinstance(end_year, str):
        end_year = int(end_year)
    
    if return_days:        
        if start_year == end_year:
            days_year = len(pd.date_range(str(start_year),
                                          str(start_year+1),
                                          inclusive="left"))       
            return days_year
            
        else:
            days_per_year = [len(pd.date_range(str(year),
                                               str(year+1),
                                               inclusive="left"))
                             for year in range(start_year, end_year+1)]
            return days_per_year
        
    else:
        if start_year == end_year:
            is_leap_year = calendar.isleap(start_year)
            return is_leap_year
        
        else:
            is_leap_year_arr = [calendar.isleap(year)
                                for year in range(start_year, end_year+1)]
            return is_leap_year_arr
